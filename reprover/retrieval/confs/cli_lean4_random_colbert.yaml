seed_everything: 3407  # https://arxiv.org/abs/2109.08203
trainer:
  accelerator: gpu
  devices: 1
  precision: bf16-mixed
  strategy:
    class_path: pytorch_lightning.strategies.DeepSpeedStrategy
    init_args:
      stage: 2
      offload_optimizer: false
      cpu_checkpointing: false
  gradient_clip_val: 1.0
  max_steps: 800000
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        verbose: true
        save_top_k: 1
        save_last: true
        monitor: val/Recall@10
        mode: max
  check_val_every_n_epoch: 2

  logger:
    class_path: pytorch_lightning.loggers.WandbLogger
    init_args:
      project: lean-colbert

model:
  config:
    checkpoint: kaiyuy/leandojo-lean4-retriever-byt5-small
    collection: ../../../data/leandojo_benchmark_4/random/collection.tsv
    index_name: colbert_v1
    experiment: lean
    root: ../../../experiments/
    warmup: 20000
    lr: 1e-5
    num_retrieved: 100
    n_log_premises: 10
    nway: 1
    query_maxlen: 128
    doc_maxlen: 180
    mask_punctuation: false
    debug: false
    ignore_scores: true

    nbits: 1
    kmeans_niters: 20
    resume: false
    similarity: cosine
    relu: false
    use_ib_negatives: true
    drop_duplciate_passages: false
    reranker: false
    distillation_alpha: 1.0
    ignore_scores: false
    attend_to_mask_tokens: false
    interaction: colbert
    dim: 128
    overwrite: false

data:
  data_path: data/leandojo_benchmark_4/random/
  batch_size: 4  # training batch size
  eval_batch_size: 16 # the batch size will be used for corpus reindexing
  num_workers: 0