seed_everything: 3407  # https://arxiv.org/abs/2109.08203
trainer:
  accelerator: gpu
  devices: 1
  precision: bf16-mixed
  strategy:
    class_path: pytorch_lightning.strategies.DeepSpeedStrategy
    init_args:
      stage: 2
      offload_optimizer: false
      cpu_checkpointing: false
  # strategy:
  #   class_path: pytorch_lightning.strategies.FSDPStrategy
  #   init_args:
  #     stage: 2
  #     offload_optimizer: false
  #     cpu_checkpointing: false
  gradient_clip_val: 1.0
  max_steps: 800000
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        verbose: true
        save_top_k: 1
        save_last: true
        monitor: val/Recall@10
        mode: max
  check_val_every_n_epoch: 2

  logger:
    class_path: pytorch_lightning.loggers.WandbLogger
    init_args:
      project: lean-colbert

model:
  config:
    checkpoint: microsoft/deberta-v3-xsmall # kaiyuy/leandojo-lean4-retriever-byt5-small
    collection: ../../../data/leandojo_benchmark_4/random/collection.tsv
    index_name: colbert_v1.1
    experiment: lean
    root: ../../../experiments/
    warmup: 20000
    lr: 1e-5
    num_retrieved: 100
    n_log_premises: 10
    query_maxlen: 128
    doc_maxlen: 180
    mask_punctuation: false
    debug: false
    ignore_scores: true
    num_negatives: 8
    num_in_file_negatives: 4
    nway: -1

    nbits: 2
    kmeans_niters: 20
    resume: false
    similarity: cosine
    relu: false
    use_ib_negatives: true
    drop_duplciate_passages: false
    reranker: false
    distillation_alpha: 1.0
    attend_to_mask_tokens: false
    interaction: colbert
    dim: 128
    overwrite: false

data:
  corpus_path: ../../../data/leandojo_benchmark_4/corpus.jsonl
  data_dir: data/leandojo_benchmark_4/random/
  batch_size: 16  # training batch size
  eval_batch_size: 80 # the batch size will be used for corpus reindexing
  num_workers: 0