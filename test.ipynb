{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d56928b-111b-4e12-9628-4d7dbb05a3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 0: export: `=native': not a valid identifier\n"
     ]
    }
   ],
   "source": [
    "!export CONTAINER=native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "638f413b-8ddd-48ca-93b0-0f8854c8c45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-11 21:38:01,742] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from generator.datamodule import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "360b3bfc-96fb-43ee-bb88-da49bd96d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, ByT5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f6025cc-3e25-4f7d-9543-ada4684ead0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ByT5Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "769787a0-98d9-4d85-a077-5d515f694c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5e0f260-6167-4337-a31e-aad9c3504dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"kaiyuy/leandojo-lean3-tacgen-byt5-small\")       # Or \"lean3\" -> \"lean4\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"kaiyuy/leandojo-lean3-tacgen-byt5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c9eab11-f95c-4ea9-9c1c-ebf2e3b380b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.t5.modeling_t5.T5ForConditionalGeneration"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6571bee-48da-401e-a719-8abe6e38004a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.t5.modeling_t5.T5Stack"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "520424f9-3717-4529-adba-839c59e3fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = \"n : ℕ\\n⊢ gcd n n = n\"\n",
    "tokenized_state = tokenizer(state, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b464e22a-e489-46b2-a2f5-a476e55e895b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24, 1472])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder(tokenized_state.input_ids)['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86e43e22-8694-42f2-a549-c394ef414ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simp [<a>nat.gcd</a>]\n",
      "unfold gcd\n",
      "rw [<a>nat.gcd_comm</a>]\n",
      "rw [<a>nat.gcd</a>, <a>nat.gcd_self_right</a>]\n"
     ]
    }
   ],
   "source": [
    "tactic_candidates_ids = model.generate(\n",
    "    tokenized_state.input_ids,\n",
    "    max_length=1024,\n",
    "    num_beams=4,\n",
    "    length_penalty=0.0,\n",
    "    do_sample=False,\n",
    "    num_return_sequences=4,\n",
    "    early_stopping=False,\n",
    ")\n",
    "tactic_candidates = tokenizer.batch_decode(\n",
    "    tactic_candidates_ids, skip_special_tokens=True\n",
    ")\n",
    "for tac in tactic_candidates:\n",
    "    print(tac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65abbce6-f5e9-4eaf-9819-6818522b7e83",
   "metadata": {},
   "source": [
    "tactic_candidates_ids = model.generate(\n",
    "    encoder_outputs=model.encoder(tokenized_state.input_ids),\n",
    "    max_length=1024,\n",
    "    num_beams=4,\n",
    "    length_penalty=0.0,\n",
    "    do_sample=False,\n",
    "    num_return_sequences=4,\n",
    "    early_stopping=False,\n",
    ")\n",
    "tactic_candidates = tokenizer.batch_decode(\n",
    "    tactic_candidates_ids, skip_special_tokens=True\n",
    ")\n",
    "for tac in tactic_candidates:\n",
    "    print(tac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab7f486b-53ce-47b4-959e-0af271fea906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ INPUT ------\n",
      " def <a>nat.gcd</a> : nat → nat → nat\n",
      "| 0        y := y\n",
      "| (succ x) y := have y % succ x < succ x, from mod_lt _ $ succ_pos _,\n",
      "                gcd (y % succ x) (succ x)\n",
      "\n",
      "@[simp] theorem <a>nat.mod_self</a> (n : nat) : n % n = 0\n",
      "\n",
      "n : ℕ\n",
      "⊢ gcd n n = n\n",
      "torch.Size([1, 255])\n",
      "torch.Size([1, 255])\n",
      "torch.Size([1, 8])\n",
      "tensor(0.1879, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "------ OUTPUT ------\n",
      "cases n\n",
      "\n",
      "cases n\n",
      "simp [<a>nat.gcd</a>]\n",
      "induction n with n ih\n",
      "induction n with n IH\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"kaiyuy/leandojo-lean3-retriever-tacgen-byt5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"kaiyuy/leandojo-lean3-retriever-tacgen-byt5-small\")\n",
    "\n",
    "state = \"n : ℕ\\n⊢ gcd n n = n\"\n",
    "retrieved_premises = [\n",
    "  \"def <a>nat.gcd</a> : nat → nat → nat\\n| 0        y := y\\n| (succ x) y := have y % succ x < succ x, from mod_lt _ $ succ_pos _,\\n                gcd (y % succ x) (succ x)\",\n",
    "  \"@[simp] theorem <a>nat.mod_self</a> (n : nat) : n % n = 0\",\n",
    "]\n",
    "input = \"\\n\\n\".join(retrieved_premises + [state])\n",
    "print(\"------ INPUT ------\\n\", input)\n",
    "tokenized_input = tokenizer(input, return_tensors=\"pt\", max_length=2300, truncation=True)\n",
    "\n",
    "# Loss\n",
    "labels = tokenizer(\"cases n\", return_tensors=\"pt\", max_length=2300, truncation=True).input_ids\n",
    "print(tokenized_input.attention_mask.shape)\n",
    "print(tokenized_input.input_ids.shape)\n",
    "print(labels.shape)\n",
    "print(model(tokenized_input.input_ids, tokenized_input.attention_mask, labels=labels).loss)\n",
    "\n",
    "# Generate a single tactic.\n",
    "tactic_ids = model.generate(tokenized_input.input_ids, max_length=1024)\n",
    "tactic = tokenizer.decode(tactic_ids[0], skip_special_tokens=True)\n",
    "print(\"\\n------ OUTPUT ------\")\n",
    "print(tactic, end=\"\\n\\n\")\n",
    "\n",
    "# Generate multiple tactics via beam search.\n",
    "tactic_candidates_ids = model.generate(\n",
    "    tokenized_input.input_ids,\n",
    "    max_length=1024,\n",
    "    num_beams=4,\n",
    "    length_penalty=0.0,\n",
    "    do_sample=False,\n",
    "    num_return_sequences=4,\n",
    "    early_stopping=False,\n",
    ")\n",
    "tactic_candidates = tokenizer.batch_decode(\n",
    "    tactic_candidates_ids, skip_special_tokens=True\n",
    ")\n",
    "for tac in tactic_candidates:\n",
    "    print(tac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6437c830-9a26-4c13-881f-3bb831e47fe9",
   "metadata": {},
   "source": [
    "### RMT debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2f2ed0-9b45-48f6-8023-94a6684d2ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-13 10:04:24,532] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from generator.datamodule import MultipleSegmentGeneratorDataModule\n",
    "from generator.model import RMTRetrievalAugmentedGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a51936d5-76b2-47c2-84ed-3c2f68f5774f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-13 10:04:24.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcommon\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m200\u001b[0m - \u001b[1mBuilding the corpus from data/leandojo_benchmark/corpus.jsonl\u001b[0m\n",
      "\u001b[32m2023-10-13 10:04:37.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgenerator.datamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mWith retrieval data\u001b[0m\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94641/94641 [00:03<00:00, 30544.23it/s]\n",
      "\u001b[32m2023-10-13 10:05:27.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgenerator.datamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1m207631 examples loaded\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 25139.15it/s]\n",
      "\u001b[32m2023-10-13 10:05:27.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgenerator.datamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1m4866 examples loaded\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data = MultipleSegmentGeneratorDataModule(\n",
    "    model_name=\"kaiyuy/leandojo-lean3-retriever-byt5-small\",\n",
    "    data_path=\"data/leandojo_benchmark/random/\",\n",
    "    corpus_path=\"data/leandojo_benchmark/corpus.jsonl\",\n",
    "    keep_marks=True,\n",
    "    preds_path=\"pred_random.pickle\",\n",
    "    batch_size=8,  # effective_batch_size == batch_size * accumulate_grad_batches * devices\n",
    "    eval_batch_size=64,\n",
    "    max_seq_len=2280,\n",
    "    num_segments=2,\n",
    "    p_drop=0.5,\n",
    "    normalize_tactics=True,\n",
    "    num_workers=2,\n",
    ")\n",
    "data.setup()\n",
    "\n",
    "train_dataloader = data.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f59c524-2612-4206-8976-96b995916554",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-13 10:05:27.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgenerator.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m110\u001b[0m - \u001b[1mLoading the retriever from ../leandojo-pl-ckpts/retriever_random.ckpt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing zero checkpoint '../leandojo-pl-ckpts/retriever_random.ckpt/checkpoint'\n",
      "Detected checkpoint of type zero stage 2, world_size: 1\n",
      "Parsing checkpoint created by deepspeed==0.9.2\n",
      "Reconstructed fp32 state dict with 111 params 217657472 elements\n",
      "Saving fp32 state dict to /tmp/tmpqk1igna0/lightning.cpkt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nesterov-va/lean_dojo/lean_dojo_env/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:161: UserWarning: Found keys that are in the model state dict but not in the checkpoint: ['encoder.encoder.embed_tokens.weight']\n",
      "  rank_zero_warn(\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at kaiyuy/leandojo-lean3-retriever-byt5-small and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'lm_head.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.final_layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RMTRetrievalAugmentedGenerator(\n",
    "    backbone_model_name=\"kaiyuy/leandojo-lean3-retriever-byt5-small\",\n",
    "    num_memory_tokens=10,\n",
    "    lr=5e-4,\n",
    "    warmup_steps=2000,\n",
    "    num_beams=1,\n",
    "    length_penalty=0.0,\n",
    "    ret_ckpt_path=\"../leandojo-pl-ckpts/retriever_random.ckpt\",\n",
    "    eval_num_retrieved=100,\n",
    "    eval_num_cpus=12,\n",
    "    eval_num_theorems=200,\n",
    "    max_seq_len=2300,\n",
    "    num_segments=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d42a0-afb8-407f-badb-332502c92b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = None\n",
    "for t in train_dataloader:\n",
    "    ex = t\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dde46e6-3483-483a-9713-41ae0a6cf06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward(\n",
    "    ex[\"state_ids\"],\n",
    "    ex[\"state_mask\"],\n",
    "    ex[\"tactic_ids\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a83dbd3d-42d4-47eb-b193-e4a2f201eba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-13 01:49:10.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mretrieval.model\u001b[0m:\u001b[36mreindex_corpus\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mRe-indexing the retrieval corpus\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PremiseRetriever' object has no attribute 'corpus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSeq2SeqLM\n\u001b[0;32m----> 3\u001b[0m tactic_candidates_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mi : int\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m⊢ gcd i i = nat_abs i\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msrc/data/int/gcd.lean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtheorem_full_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint.gcd_self\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtheorem_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m195\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m tactic_candidates \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(\n\u001b[1;32m     11\u001b[0m     tactic_candidates_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tac \u001b[38;5;129;01min\u001b[39;00m tactic_candidates:\n",
      "File \u001b[0;32m~/lean_dojo/ReProver/generator/model.py:285\u001b[0m, in \u001b[0;36mRetrievalAugmentedGenerator.generate\u001b[0;34m(self, state, file_path, theorem_full_name, theorem_pos, num_samples)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     state: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m     num_samples: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    284\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtheorem_full_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtheorem_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/lean_dojo/ReProver/generator/model.py:529\u001b[0m, in \u001b[0;36mRMTRetrievalAugmentedGenerator.batch_generate\u001b[0;34m(self, state, file_path, theorem_full_name, theorem_pos, num_samples)\u001b[0m\n\u001b[1;32m    527\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(state)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretriever \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 529\u001b[0m retrieved_premises, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtheorem_full_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtheorem_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_num_retrieved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m segments \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_segments)]\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s, premises \u001b[38;5;129;01min\u001b[39;00m zip_strict(state, retrieved_premises):\n",
      "File \u001b[0;32m~/lean_dojo/ReProver/retrieval/model.py:346\u001b[0m, in \u001b[0;36mPremiseRetriever.retrieve\u001b[0;34m(self, state, file_name, theorem_full_name, theorem_pos, k)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve\u001b[39m(\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    339\u001b[0m     state: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    343\u001b[0m     k: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    344\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[Premise], List[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m    345\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieve ``k`` premises from ``corpus`` using ``state`` and ``tactic_prefix`` as context.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_corpus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     ctx \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    349\u001b[0m         Context(\u001b[38;5;241m*\u001b[39m_)\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m zip_strict(file_name, theorem_full_name, theorem_pos, state)\n\u001b[1;32m    351\u001b[0m     ]\n\u001b[1;32m    352\u001b[0m     ctx_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\n\u001b[1;32m    353\u001b[0m         [_\u001b[38;5;241m.\u001b[39mserialize() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m ctx],\n\u001b[1;32m    354\u001b[0m         padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    358\u001b[0m     )\n",
      "File \u001b[0;32m~/lean_dojo/lean_dojo_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/lean_dojo/ReProver/retrieval/model.py:175\u001b[0m, in \u001b[0;36mPremiseRetriever.reindex_corpus\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    172\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-indexing the retrieval corpus\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241m.\u001b[39mall_premises),\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_size,\n\u001b[1;32m    177\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    178\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m    179\u001b[0m )\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus), batch_size)):\n\u001b[1;32m    182\u001b[0m     batch_premises \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus\u001b[38;5;241m.\u001b[39mall_premises[i : i \u001b[38;5;241m+\u001b[39m batch_size]\n",
      "File \u001b[0;32m~/lean_dojo/lean_dojo_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PremiseRetriever' object has no attribute 'corpus'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tactic_candidates_ids = model.generate(\n",
    "    state=\"i : int\\n⊢ gcd i i = nat_abs i\",\n",
    "    file_path=\"src/data/int/gcd.lean\",\n",
    "    theorem_full_name=\"int.gcd_self\",\n",
    "    theorem_pos=(195,1),\n",
    "    num_samples=4,\n",
    ")\n",
    "tactic_candidates = tokenizer.batch_decode(\n",
    "    tactic_candidates_ids, skip_special_tokens=True\n",
    ")\n",
    "for tac in tactic_candidates:\n",
    "    print(tac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "079b0be3-2bf1-4548-b6d0-cdc620e1c0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator.model.RMTRetrievalAugmentedGenerator"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85cc72e3-c16c-4a9d-9d9b-a06aea4e4eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48c407f8-ca90-4c28-a7d8-8699ec647915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('src/analysis/bounded_variation.lean', 'variation_on_from_to.self', 'α : Type u_1,\\n_inst_1 : linear_order α,\\nE : Type u_3,\\n_inst_3 : pseudo_emetric_space E,\\nf : α → E,\\ns : set α,\\na : α\\n⊢ variation_on_from_to f s a a = 0')\n"
     ]
    }
   ],
   "source": [
    "key = list(data.preds.keys())[0]\n",
    "print(key)\n",
    "prem = data.preds[key]['retrieved_premises'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a8ed560-2206-461f-b58f-92db04727fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(737, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prem.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b6579c7-0cc1-45b9-a09a-5939d0f534a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://github.com/leanprover-community/mathlib',\n",
       " 'commit': '32a7e535287f9c73f2e4d2aef306a39190f0b504',\n",
       " 'file_path': 'src/analysis/calculus/diff_cont_on_cl.lean',\n",
       " 'full_name': 'diff_cont_on_cl.continuous_on_ball',\n",
       " 'state': [\"def <a>metric.ball</a> (x : α) (ε : ℝ) : set α := {y | dist y x < ε}\\n\\nlemma <a>balanced_ball_zero</a> : balanced 𝕜 (metric.ball (0 : E) r)\\n\\n@[simp] theorem <a>metric.closed_ball_diff_sphere</a> : closed_ball x ε \\\\ sphere x ε = ball x ε\\n\\ndef <a>metric.sphere</a> (x : α) (ε : ℝ) := {y | dist y x = ε}\\n\\ntheorem <a>int.preimage_closed_ball</a> (x : ℤ) (r : ℝ) :\\n  coe ⁻¹' (closed_ball (x : ℝ) r) = closed_ball x r\\n\\nlemma <a>metric.closed_ball_eq_bInter_ball</a> : closed_ball x ε = ⋂ δ > ε, ball x δ\\n\\nlemma <a>real.closed_ball_eq_Icc</a> {x r : ℝ} : closed_ball x r = Icc (x - r) (x + r)\\n\\ntheorem <a>metric.closed_ball_eq_sphere_of_nonpos</a> (hε : ε ≤ 0) : closed_ball x ε = sphere x ε\\n\\nlemma <a>seminorm.preimage_metric_closed_ball</a> {r : ℝ} :\\n  p ⁻¹' (metric.closed_ball 0 r) = {x | p x ≤ r}\\n\\n@[simp] lemma <a>metric.nonempty_ball</a> : (ball x ε).nonempty ↔ 0 < ε\\n\\n@[simp] theorem <a>metric.closed_ball_diff_ball</a> : closed_ball x ε \\\\ ball x ε = sphere x ε\\n\\ndef <a>metric.closed_ball</a> (x : α) (ε : ℝ) := {y | dist y x ≤ ε}\\n\\ndef <a>emetric.closed_ball</a> (x : α) (ε : ℝ≥0∞) := {y | edist y x ≤ ε}\\n\\nlemma <a>seminorm.balanced_closed_ball_zero</a> (r : ℝ) : balanced 𝕜 (closed_ball p 0 r)\\n\\ntheorem <a>nat.preimage_closed_ball</a> (x : ℕ) (r : ℝ) :\\n  coe ⁻¹' (closed_ball (x : ℝ) r) = closed_ball x r\\n\\nprotected lemma <a>continuous_linear_map.tmp_closed_ball_div_subset</a> {a b : ℝ} (ha : 0 < a) (hb : 0 < b) :\\n  closed_ball (0 : E →SL[σ₁₂] F) (a / b) ⊆\\n  {f | ∀ x ∈ closed_ball (0 : E) b, f x ∈ closed_ball (0 : F) a}\\n\\nclass <a>proper_space</a> (α : Type u) [pseudo_metric_space α] : Prop :=\\n(is_compact_closed_ball : ∀x:α, ∀r, is_compact (closed_ball x r))\\n\\ntheorem <a>metric.closed_ball_mem_nhds_of_mem</a> {x c : α} {ε : ℝ} (h : x ∈ ball c ε) :\\n  closed_ball c ε ∈ 𝓝 x\\n\\n𝕜 : Type u_1,\\nE : Type u_2,\\nF : Type u_3,\\n_inst_1 : nontrivially_normed_field 𝕜,\\n_inst_2 : normed_add_comm_group E,\\n_inst_3 : normed_add_comm_group F,\\n_inst_4 : normed_space 𝕜 E,\\n_inst_5 : normed_space 𝕜 F,\\nf : E → F,\\n_inst_8 : normed_space ℝ E,\\nx : E,\\nr : ℝ,\\nh : diff_cont_on_cl 𝕜 f (ball x r)\\n⊢ continuous_on f (closed_ball x r)\",\n",
       "  \"lemma <a>metric.bounded_ball</a> : bounded (ball x r)\\n\\nlemma <a>seminorm.preimage_metric_closed_ball</a> {r : ℝ} :\\n  p ⁻¹' (metric.closed_ball 0 r) = {x | p x ≤ r}\\n\\ntheorem <a>metric.mem_closed_ball'</a> : y ∈ closed_ball x ε ↔ dist x y ≤ ε\\n\\ntheorem <a>metric.sphere_subset_closed_ball</a> : sphere x ε ⊆ closed_ball x ε\\n\\ndef <a>metric.closed_ball</a> (x : α) (ε : ℝ) := {y | dist y x ≤ ε}\\n\\ndef <a>emetric.closed_ball</a> (x : α) (ε : ℝ≥0∞) := {y | edist y x ≤ ε}\\n\\nlemma <a>seminorm.balanced_closed_ball_zero</a> (r : ℝ) : balanced 𝕜 (closed_ball p 0 r)\\n\\ntheorem <a>interior_closed_ball'</a> [normed_space ℝ E] [nontrivial E] (x : E) (r : ℝ) :\\n  interior (closed_ball x r) = ball x r\\n\\ntheorem <a>emetric.ball_subset_closed_ball</a> : ball x ε ⊆ closed_ball x ε\\n\\n@[simp] lemma <a>metric.closed_ball_eq_empty</a> : closed_ball x ε = ∅ ↔ ε < 0\\n\\nclass <a>proper_space</a> (α : Type u) [pseudo_metric_space α] : Prop :=\\n(is_compact_closed_ball : ∀x:α, ∀r, is_compact (closed_ball x r))\\n\\nlemma <a>metric.closed_ball_subset_closed_ball'</a> (h : ε₁ + dist x y ≤ ε₂) :\\n  closed_ball x ε₁ ⊆ closed_ball y ε₂\\n\\n@[simp] lemma <a>metric.closed_ball_zero</a> : closed_ball x 0 = {x}\\n\\nlemma <a>seminorm.ball_subset_closed_ball</a> (x r) : ball p x r ⊆ closed_ball p x r\\n\\nlemma <a>metric.closed_ball_subset_ball'</a> (h : ε₁ + dist x y < ε₂) :\\n  closed_ball x ε₁ ⊆ ball y ε₂\\n\\n@[simp] theorem <a>metric.closure_closed_ball</a> : closure (closed_ball x ε) = closed_ball x ε\\n\\nlemma <a>seminorm.closed_ball_zero_eq_preimage_closed_ball</a> {r : ℝ} :\\n  p.closed_ball 0 r = p ⁻¹' (metric.closed_ball 0 r)\\n\\ntheorem <a>metric.closure_ball_subset_closed_ball</a> : closure (ball x ε) ⊆ closed_ball x ε\\n\\ntheorem <a>closure_ball</a> [normed_space ℝ E] (x : E) {r : ℝ} (hr : r ≠ 0) :\\n  closure (ball x r) = closed_ball x r\\n\\n𝕜 : Type u_1,\\nE : Type u_2,\\nF : Type u_3,\\n_inst_1 : nontrivially_normed_field 𝕜,\\n_inst_2 : normed_add_comm_group E,\\n_inst_3 : normed_add_comm_group F,\\n_inst_4 : normed_space 𝕜 E,\\n_inst_5 : normed_space 𝕜 F,\\nf : E → F,\\n_inst_8 : normed_space ℝ E,\\nx : E,\\nr : ℝ,\\nh : diff_cont_on_cl 𝕜 f (ball x r)\\n⊢ continuous_on f (closed_ball x r)\"],\n",
       " 'tactic': 'rcases <a>eq_or_ne</a> r 0 with rfl|hr'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ds_train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5412c5b1-67c1-41a8-a11f-0d66cf4994b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95cefb5b-a85c-45cf-b40d-1a03eb7ca5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.arange(5).unsqueeze(0)\n",
    "labels = torch.arange(5, 12).unsqueeze(0)\n",
    "attention_mask = torch.ones(5)\n",
    "attention_mask[[0, 2, 4]] = 0\n",
    "attention_mask = attention_mask.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cf12b9a-d4b0-4a5a-8cfc-853f3bba5118",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.generator.forward(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    labels=labels,\n",
    "    #output_hidden_states=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6222ed1d-78ad-4078-8426-b4a0b5db50b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(105.0325, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d092cfb-891a-4d1f-b475-8796255a85fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits', 'past_key_values', 'decoder_hidden_states', 'encoder_last_hidden_state', 'encoder_hidden_states'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a75d6e75-a668-4182-8d6c-28720cc67ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.generator.forward(\n",
    "    encoder_outputs=(enc_out,),\n",
    "    attention_mask=attention_mask,\n",
    "    labels=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3892263f-7956-441f-9b89-5ef57e19dcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(105.0325, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da34596-9f58-4f36-8c38-127b9bc453a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
